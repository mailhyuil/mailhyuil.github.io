"use strict";(globalThis.webpackChunkmy_blog=globalThis.webpackChunkmy_blog||[]).push([[238268],{529087:(e,n,t)=>{t.d(n,{R:()=>o,x:()=>c});var a=t(596363);const s={},r=a.createContext(s);function o(e){const n=a.useContext(r);return a.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),a.createElement(r.Provider,{value:n},e.children)}},699267:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>i,contentTitle:()=>c,default:()=>m,frontMatter:()=>o,metadata:()=>a,toc:()=>l});const a=JSON.parse('{"id":"ai langchain/langchain prompt Prompt Templates","title":"langchain Prompt Templates","description":"\uc77c\ubc18 message \ud568\uc218\ub97c \uc0ac\uc6a9\ud558\uba74 \ub370\uc774\ud130\ub4e4\uc744 \uc804\ubd80 string\uc73c\ub85c \ubcc0\ud658\ud574\uc11c \uc0ac\uc6a9\ud574\uc57c\ud55c\ub2e4.","source":"@site/docs/ai langchain/langchain prompt Prompt Templates.md","sourceDirName":"ai langchain","slug":"/ai langchain/langchain prompt Prompt Templates","permalink":"/docs/ai langchain/langchain prompt Prompt Templates","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"langchain Prompt Templates nested promptMessages","permalink":"/docs/ai langchain/langchain prompt Prompt Templates MessagePlaceholder"},"next":{"title":"langchain Classification & Extract Structured Output","permalink":"/docs/ai langchain/langchain respond Classification & Extract Structured Output"}}');var s=t(447259),r=t(529087);const o={},c="langchain Prompt Templates",i={},l=[];function p(e){const n={blockquote:"blockquote",code:"code",h1:"h1",header:"header",p:"p",pre:"pre",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"langchain-prompt-templates",children:"langchain Prompt Templates"})}),"\n",(0,s.jsxs)(n.blockquote,{children:["\n",(0,s.jsx)(n.p,{children:"\uc77c\ubc18 message \ud568\uc218\ub97c \uc0ac\uc6a9\ud558\uba74 \ub370\uc774\ud130\ub4e4\uc744 \uc804\ubd80 string\uc73c\ub85c \ubcc0\ud658\ud574\uc11c \uc0ac\uc6a9\ud574\uc57c\ud55c\ub2e4."}),"\n",(0,s.jsxs)(n.blockquote,{children:["\n",(0,s.jsx)(n.p,{children:"Prompt Templates\ub97c \uc0ac\uc6a9\ud558\uba74 \ub370\uc774\ud130\ub97c \ub354 \uc27d\uac8c \ubc30\uc5f4\ub85c \ub123\uc744 \uc218 \uc788\ub2e4."}),"\n",(0,s.jsxs)(n.blockquote,{children:["\n",(0,s.jsx)(n.p,{children:"roles : system, user(human), assistant(ai)"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-ts",children:'import { ChatPromptTemplate } from "@langchain/core/prompts";\r\n\r\nconst { message, language } = data;\r\n\r\nconst systemMessages = getSystemMessages();\r\n\r\nconst promptTemplate = ChatPromptTemplate.fromMessages([\r\n  ["system", "Translate the following from English into {language}, " + systemMessages.join("\\n")],\r\n  ["user", "{message}"],\r\n]);\r\n\r\nconst promptValue = await promptTemplate.invoke({\r\n  language,\r\n  message,\r\n});\r\n\r\nconst stream = await this.model.stream(promptValue);\r\nconst chunks = [];\r\nfor await (const chunk of stream) {\r\n  chunks.push(chunk);\r\n  res.write(chunk.content.toString());\r\n}\r\nres.end();\n'})})]})}function m(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(p,{...e})}):p(e)}}}]);