"use strict";(self.webpackChunkmy_blog=self.webpackChunkmy_blog||[]).push([["991529"],{408255:function(n,e,r){r.r(e),r.d(e,{frontMatter:()=>i,toc:()=>l,default:()=>g,metadata:()=>t,assets:()=>c,contentTitle:()=>o});var t=JSON.parse('{"id":"ai langchain/langchain \uC138\uD305 settings openai","title":"langchain","description":"install","source":"@site/docs/ai langchain/langchain \uC138\uD305 settings openai.md","sourceDirName":"ai langchain","slug":"/ai langchain/langchain \uC138\uD305 settings openai","permalink":"/docs/ai langchain/langchain \uC138\uD305 settings openai","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"langchain settings local","permalink":"/docs/ai langchain/langchain \uC138\uD305 settings ollama - local"},"next":{"title":"API","permalink":"/docs/category/api"}}'),s=r(447259),a=r(255511);let i={},o="langchain",c={},l=[{value:"install",id:"install",level:2},{value:"gpt.service.ts",id:"gptservicets",level:2},{value:"gpt.controller.ts",id:"gptcontrollerts",level:2},{value:"client",id:"client",level:2}];function p(n){let e={code:"code",h1:"h1",h2:"h2",header:"header",pre:"pre",...(0,a.R)(),...n.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(e.header,{children:(0,s.jsx)(e.h1,{id:"langchain",children:"langchain"})}),"\n",(0,s.jsx)(e.h2,{id:"install",children:"install"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-sh",children:"npm i langchain\r\nnpm i @langchain/core\r\nnpm i @langchain/openai\r\n\r\n# client polyfill\r\nnpm i web-streams-polyfill@4\n"})}),"\n",(0,s.jsx)(e.h2,{id:"gptservicets",children:"gpt.service.ts"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-js",children:"import { HumanMessage, SystemMessage } from '@langchain/core/messages';\r\nimport { ChatPromptTemplate } from '@langchain/core/prompts';\r\nimport { ChatOpenAI } from '@langchain/openai';\r\nimport { Injectable } from '@nestjs/common';\r\nimport { Subject } from 'rxjs';\r\n\r\n@Injectable()\r\nexport class GptService {\r\n  connections = new Map<\r\n    string,\r\n    Subject<MessageEvent<{ chunk: string } | 'keep-alive'>>\r\n  >();\r\n  model = new ChatOpenAI({\r\n    model: 'gpt-4o-mini',\r\n    apiKey: process.env['OPENAI_API_KEY'], // \uD658\uACBD\uBCC0\uC218\uC5D0\uC11C API \uD0A4 \uB85C\uB4DC\r\n  });\r\n\r\n  create(id: string) {\r\n    if (!this.connections.has(id)) {\r\n      this.connections.set(\r\n        id,\r\n        new Subject<MessageEvent<{ chunk: string } | 'keep-alive'>>(),\r\n      );\r\n    }\r\n    const subject$ = this.connections.get(id);\r\n\r\n    return subject$;\r\n  }\r\n  deleteConnection(id: string) {\r\n    this.connections.delete(id);\r\n  }\r\n\r\n  async message(data: { id: string; message: string }) {\r\n    const { id, message } = data;\r\n    const messages = [\r\n      new SystemMessage('Translate the following from English into Korean'),\r\n      new HumanMessage(message),\r\n    ];\r\n\r\n    const stream = await this.model.stream(messages);\r\n\r\n    const subject$ = this.create(id);\r\n    const chunks = [];\r\n    for await (const chunk of stream) {\r\n      chunks.push(chunk);\r\n      subject$.next({\r\n        data: { chunk: chunk.content.toString() },\r\n      } as MessageEvent<{ chunk: string }>);\r\n    }\r\n    // store the chunks in the database\r\n  }\r\n\r\n  async template(data: { id: string; message: string }) {\r\n    const { id, message } = data;\r\n    const promptTemplate = ChatPromptTemplate.fromMessages([\r\n      ['system', 'Translate the following from English into {language}'],\r\n      ['user', '{message}'],\r\n    ]);\r\n\r\n    const promptValue = await promptTemplate.invoke({\r\n      language: 'korean',\r\n      message,\r\n    });\r\n\r\n    const stream = await this.model.stream(promptValue);\r\n    const subject$ = this.create(id);\r\n    const chunks = [];\r\n    for await (const chunk of stream) {\r\n      chunks.push(chunk);\r\n      subject$.next({\r\n        data: { chunk: chunk.content.toString() },\r\n      } as MessageEvent<{\r\n        chunk: string;\r\n      }>);\r\n    }\r\n    // store the chunks in the database\r\n  }\r\n}\n"})}),"\n",(0,s.jsx)(e.h2,{id:"gptcontrollerts",children:"gpt.controller.ts"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-js",children:"import { Body, Controller, Param, Post, Res, Sse } from '@nestjs/common';\r\nimport { ApiTags } from '@nestjs/swagger';\r\nimport { Response } from 'express';\r\nimport { interval } from 'rxjs';\r\nimport { GptService } from './gpt.service';\r\n\r\n@ApiTags('Gpt')\r\n@Controller({ path: 'gpt', version: '1' })\r\nexport class GptController {\r\n  constructor(private readonly gptService: GptService) {}\r\n\r\n  @Post('message')\r\n  async message(@Body() body: { id: string; message: string }) {\r\n    await this.gptService.message(body);\r\n  }\r\n\r\n  @Post('template')\r\n  async template(@Body() body: { id: string; message: string }) {\r\n    await this.gptService.template(body);\r\n  }\r\n\r\n  @Sse(':id')\r\n  async connect(\r\n    @Param('id') id: string,\r\n    @Res({ passthrough: true }) res: Response,\r\n  ) {\r\n    const subject$ = this.gptService.create(id);\r\n\r\n    // keep-alive\r\n    const subscription = interval(1000 * 60 * 30).subscribe(() => {\r\n      subject$.next({ data: 'keep-alive' } as MessageEvent<'keep-alive'>);\r\n    });\r\n    res.on('close', () => {\r\n      this.gptService.deleteConnection(id);\r\n      subject$.complete();\r\n      subscription.unsubscribe();\r\n    });\r\n    return subject$.asObservable();\r\n  }\r\n}\n"})}),"\n",(0,s.jsx)(e.h2,{id:"client",children:"client"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-ts",children:'import { HttpClient } from "@angular/common/http";\r\nimport { Component, inject, signal } from "@angular/core";\r\nimport { takeUntilDestroyed } from "@angular/core/rxjs-interop";\r\nimport { fromEvent } from "rxjs";\r\n\r\n@Component({\r\n  selector: "app-greeting",\r\n  templateUrl: "./greeting.component.html",\r\n  imports: [],\r\n  standalone: true,\r\n})\r\nexport class GreetingComponent {\r\n  http = inject(HttpClient);\r\n  content = signal("");\r\n  eventSource?: EventSource;\r\n  id = Math.random().toString(36).substring(7);\r\n\r\n  constructor() {\r\n    if (!this.eventSource) {\r\n      this.eventSource = new EventSource(`http://localhost:3000/api/v1/gpt/${this.id}`, {\r\n        withCredentials: false,\r\n      });\r\n    }\r\n    fromEvent(this.eventSource, "open")\r\n      .pipe(takeUntilDestroyed())\r\n      .subscribe(() => {\r\n        console.log("connected");\r\n      });\r\n    fromEvent(this.eventSource, "error")\r\n      .pipe(takeUntilDestroyed())\r\n      .subscribe(error => {\r\n        console.error(error);\r\n      });\r\n    fromEvent<MessageEvent<string>>(this.eventSource, "message")\r\n      .pipe(takeUntilDestroyed())\r\n      .subscribe(({ data }) => {\r\n        if (data === "keep-alive") return;\r\n        const { chunk } = JSON.parse(data);\r\n        this.content.update(prev => prev + chunk);\r\n      });\r\n  }\r\n\r\n  onClick() {\r\n    this.http\r\n      .post(`http://localhost:3000/api/v1/gpt/message`, {\r\n        id: this.id,\r\n        message: "Hello, World!",\r\n      })\r\n      .subscribe();\r\n  }\r\n\r\n  onDestroy() {\r\n    this.eventSource?.close();\r\n    this.eventSource = undefined;\r\n  }\r\n}\n'})})]})}function g(n={}){let{wrapper:e}={...(0,a.R)(),...n.components};return e?(0,s.jsx)(e,{...n,children:(0,s.jsx)(p,{...n})}):p(n)}},255511:function(n,e,r){r.d(e,{R:()=>i,x:()=>o});var t=r(596363);let s={},a=t.createContext(s);function i(n){let e=t.useContext(a);return t.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function o(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(s):n.components||s:i(n.components),t.createElement(a.Provider,{value:e},n.children)}}}]);