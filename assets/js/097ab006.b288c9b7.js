"use strict";(globalThis.webpackChunkmy_blog=globalThis.webpackChunkmy_blog||[]).push([[555438],{529087:(n,e,a)=>{a.d(e,{R:()=>t,x:()=>i});var o=a(596363);const r={},s=o.createContext(r);function t(n){const e=o.useContext(s);return o.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function i(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(r):n.components||r:t(n.components),o.createElement(s.Provider,{value:e},n.children)}},566271:(n,e,a)=>{a.r(e),a.d(e,{assets:()=>l,contentTitle:()=>i,default:()=>h,frontMatter:()=>t,metadata:()=>o,toc:()=>d});const o=JSON.parse('{"id":"ai langchain/langchain LangGraph graph - workflow","title":"langchain LangGraph graph (workflow)","description":"addNode","source":"@site/docs/ai langchain/langchain LangGraph graph - workflow.md","sourceDirName":"ai langchain","slug":"/ai langchain/langchain LangGraph graph - workflow","permalink":"/docs/ai langchain/langchain LangGraph graph - workflow","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"langchain LangGraph custom agent","permalink":"/docs/ai langchain/langchain LangGraph custom agent"},"next":{"title":"langchain LangGraph","permalink":"/docs/ai langchain/langchain LangGraph"}}');var r=a(447259),s=a(529087);const t={},i="langchain LangGraph graph (workflow)",l={},d=[{value:"addNode",id:"addnode",level:2},{value:"addEdge",id:"addedge",level:2},{value:"addConditionalEdges",id:"addconditionaledges",level:2},{value:"define a new graph",id:"define-a-new-graph",level:2},{value:"use the graph",id:"use-the-graph",level:2}];function c(n){const e={blockquote:"blockquote",code:"code",h1:"h1",h2:"h2",header:"header",p:"p",pre:"pre",...(0,s.R)(),...n.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(e.header,{children:(0,r.jsx)(e.h1,{id:"langchain-langgraph-graph-workflow",children:"langchain LangGraph graph (workflow)"})}),"\n",(0,r.jsx)(e.h2,{id:"addnode",children:"addNode"}),"\n",(0,r.jsxs)(e.blockquote,{children:["\n",(0,r.jsx)(e.p,{children:"\ub178\ub4dc \ud568\uc218 \ucd94\uac00"}),"\n",(0,r.jsxs)(e.blockquote,{children:["\n",(0,r.jsx)(e.p,{children:"\ud2b9\uc218\ud55c \uc561\uc158\uc744 \uc218\ud589\ud558\uac70\ub098 (tool), \ubaa8\ub378\uc744 \ud638\ucd9c\ud558\ub294 \ud568\uc218\ub97c \uc815\uc758"}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"addedge",children:"addEdge"}),"\n",(0,r.jsxs)(e.blockquote,{children:["\n",(0,r.jsx)(e.p,{children:"\uc5e3\uc9c0 \ucd94\uac00"}),"\n",(0,r.jsxs)(e.blockquote,{children:["\n",(0,r.jsx)(e.p,{children:"\uc5e3\uc9c0\ub294 \ub178\ub4dc \uac04\uc758 \uc5f0\uacb0\uc744 \ub098\ud0c0\ub0b4\uba70, \ub178\ub4dc \uac04\uc758 \uc774\ub3d9\uc744 \uc81c\uc5b4"}),"\n",(0,r.jsxs)(e.blockquote,{children:["\n",(0,r.jsx)(e.p,{children:"'agent', 'tools', '__start__', '__end__' \ub4f1\uc758 \uac12\uc744 \uc0ac\uc6a9\ud574\uc11c \ud2b9\uc815 \ub178\ub4dc\ub85c \uc774\ub3d9"}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.code,{children:'import {START, END} from "@langchain/langgraph";'})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"addconditionaledges",children:"addConditionalEdges"}),"\n",(0,r.jsxs)(e.blockquote,{children:["\n",(0,r.jsx)(e.p,{children:"\uc870\uac74\ubd80 \uc5e3\uc9c0 \ud568\uc218 \ucd94\uac00"}),"\n",(0,r.jsxs)(e.blockquote,{children:["\n",(0,r.jsx)(e.p,{children:"\ud568\uc218\ub97c \ud1b5\ud574 \uc870\uac74\uc744 \ub9cc\uc871\ud558\ub294 \uacbd\uc6b0 \uc5e3\uc9c0 \uac12\uc744 \ubc18\ud658\ud558\uc5ec \ud2b9\uc815 \ub178\ub4dc\ub85c \uc774\ub3d9"}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"define-a-new-graph",children:"define a new graph"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-ts",children:'import { ToolNode } from "@langchain/langgraph/prebuilt";\r\nimport { tool } from "@langchain/core/tools";\r\nimport { ChatOpenAI } from "@langchain/openai";\r\nimport { HumanMessage, AIMessage } from "@langchain/core/messages";\r\nimport { StateGraph, MessagesAnnotation } from "@langchain/langgraph";\r\n\r\nconst sayHi = tool(\r\n  ({ name }: { name: string }): void => {\r\n    console.log(`Hi, ${name}!`);\r\n  },\r\n  {\r\n    name: "sayHi",\r\n    description: "say Hi with user\'s name if provided",\r\n    // input schema\r\n    schema: z.object({\r\n      name: z.string(),\r\n    }),\r\n  },\r\n);\r\n\r\nconst sayGoodbye = tool(\r\n  ({ name }: { name: string }): void => {\r\n    console.log(`Hi, ${name}!`);\r\n  },\r\n  {\r\n    name: "sayGoodbye",\r\n    description: "say goodbye with user\'s name if provided",\r\n    // input schema\r\n    schema: z.object({\r\n      name: z.string(),\r\n    }),\r\n  },\r\n);\r\n\r\n// Define the tools for the agent to use\r\nconst tools = [sayHi, sayGoodbye];\r\nconst toolNode = new ToolNode(tools);\r\n\r\n// Create a model and give it access to the tools\r\nconst model = new ChatOpenAI({\r\n  model: "gpt-4o-mini",\r\n  temperature: 0,\r\n}).bindTools(tools);\r\n\r\n// \uacc4\uc18d\ud560\uc9c0 \ub9d0\uc9c0 \uacb0\uc815\ud558\ub294 \ud568\uc218 \uc815\uc758\r\nfunction shouldContinue({ messages }: typeof MessagesAnnotation.State) {\r\n  const lastMessage = messages[messages.length - 1] as AIMessage;\r\n  // \ub3c4\uad6c \ud638\ucd9c\uc774 \uc788\uc73c\uba74 "tools" \ub178\ub4dc\ub85c \ub77c\uc6b0\ud305\r\n  if (lastMessage.tool_calls?.length) {\r\n    return "tools";\r\n  }\r\n  // \uadf8\ub807\uc9c0 \uc54a\uc73c\uba74 \ud2b9\uc218\ud55c "__end__" \ub178\ub4dc\ub97c \uc0ac\uc6a9\ud558\uc5ec \uba48\ucda4\r\n  return "__end__";\r\n}\r\n\r\n// \ubaa8\ub378\uc744 \ud638\ucd9c\ud558\ub294 \ud568\uc218 \uc815\uc758\r\nasync function callModel(state: typeof MessagesAnnotation.State) {\r\n  const response = await model.invoke(state.messages);\r\n  // \uae30\uc874 \ubaa9\ub85d\uc5d0 \ucd94\uac00\ub418\uae30 \ub54c\ubb38\uc5d0 \ubaa9\ub85d\uc744 \ubc18\ud658\r\n  return { messages: [response] };\r\n}\r\n\r\n// Define a new graph\r\nconst workflow = new StateGraph(MessagesAnnotation)\r\n  .addNode("agent", callModel)\r\n  .addEdge("__start__", "agent") // __start__ is a special name for the entrypoint\r\n  .addNode("tools", toolNode)\r\n  .addEdge("tools", "agent")\r\n  .addConditionalEdges("agent", shouldContinue);\r\n\r\n// Finally, we compile it into a LangChain Runnable.\r\nconst app = workflow.compile();\n'})}),"\n",(0,r.jsx)(e.h2,{id:"use-the-graph",children:"use the graph"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-ts",children:'// \uccab\ubc88\uc9f8 \uc0ac\uc6a9\uc790 \uba54\uc2dc\uc9c0\ub97c \uc2e4\ud589 \uccab\ubc88\uc9f8 \ub178\ub4dc\ub85c \uc774\ub3d9\r\nconst finalState = await app.invoke({\r\n  messages: [new HumanMessage("Hi, My name is John")],\r\n});\r\n\r\nconsole.log(finalState.messages[finalState.messages.length - 1].content);\r\n// Hi, John!\r\n\r\n// \ub2e4\uc74c \uc0ac\uc6a9\uc790 \uba54\uc2dc\uc9c0\uac00 \uc624\uba74 \uc774\uc804 \uc0c1\ud0dc\ub97c \uae30\uc5b5\ud574\ub450\uace0 \uc788\ub2e4\uac00 \uadf8 \ub2e4\uc74c \ub178\ub4dc\ub85c \uc774\ub3d9\r\nconst nextState = await app.invoke({\r\n  // Including the messages from the previous run gives the LLM context.\r\n  // This way it knows we\'re asking about the weather in NY\r\n  messages: [...finalState.messages, new HumanMessage("Goodbye")],\r\n});\r\n\r\nconsole.log(nextState.messages[nextState.messages.length - 1].content);\r\n// Goodbye, John!\n'})})]})}function h(n={}){const{wrapper:e}={...(0,s.R)(),...n.components};return e?(0,r.jsx)(e,{...n,children:(0,r.jsx)(c,{...n})}):c(n)}}}]);